{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielluca00/ML_Bone_fracture_detection_DenseNet201/blob/main/bone_fracture_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQPjxftXwUHJ"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import kagglehub\n",
        "osamajalilhassan_bone_fracture_dataset_path = kagglehub.dataset_download('osamajalilhassan/bone-fracture-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:16:23.4407Z",
          "iopub.status.busy": "2024-01-12T06:16:23.439864Z",
          "iopub.status.idle": "2024-01-12T06:16:36.203648Z",
          "shell.execute_reply": "2024-01-12T06:16:36.202871Z",
          "shell.execute_reply.started": "2024-01-12T06:16:23.440667Z"
        },
        "id": "WaHWniE9wUHN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201\n",
        "from tensorflow.keras.applications import MobileNetV3Small\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, log_loss, jaccard_score\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from shutil import copyfile  # Import the copyfile function\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_ESvkqRwUHO"
      },
      "source": [
        "# **Dataset Describtion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:16:38.046386Z",
          "iopub.status.busy": "2024-01-12T06:16:38.045774Z",
          "iopub.status.idle": "2024-01-12T06:16:38.054263Z",
          "shell.execute_reply": "2024-01-12T06:16:38.050543Z",
          "shell.execute_reply.started": "2024-01-12T06:16:38.046352Z"
        },
        "id": "G5qrszSqwUHP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define the paths to our train, validation, and test datasets\n",
        "train_data_dir =  '/kaggle/input/bone-fracture-dataset/BoneFractureDataset/training'\n",
        "test_data_dir = '/kaggle/input/bone-fracture-dataset/BoneFractureDataset/testing'\n",
        "validation_data_dir = '/kaggle/input/bone-fracture-dataset/BoneFractureDataset/testing'\n",
        "\n",
        "# Image dimensions\n",
        "IMG_WIDTH, IMG_HEIGHT = 299, 299\n",
        "input_shape = (IMG_WIDTH, IMG_HEIGHT, 3)  # RGB images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrMR5FCqwUHQ"
      },
      "source": [
        "# **Data generators**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:16:43.509755Z",
          "iopub.status.busy": "2024-01-12T06:16:43.509365Z",
          "iopub.status.idle": "2024-01-12T06:16:46.911915Z",
          "shell.execute_reply": "2024-01-12T06:16:46.911117Z",
          "shell.execute_reply.started": "2024-01-12T06:16:43.509725Z"
        },
        "id": "d6CaLsgJwUHQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Data generators for RGB images\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "\n",
        "# Define data generators for RGB images with augmentation\n",
        "train_datagen_augmented = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,  # Rotation angle range\n",
        "    width_shift_range=0.2,  # Horizontal shift range\n",
        "    height_shift_range=0.2,  # Vertical shift range\n",
        "    shear_range=0.2,  # Shear intensity\n",
        "    zoom_range=0.2,  # Random zoom range\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    vertical_flip=False,  # Do not flip images vertically\n",
        "    fill_mode='nearest'  # Fill mode for newly created pixels\n",
        ")\n",
        "\n",
        "# Generate augmented data for training\n",
        "train_generator = train_datagen_augmented.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=10,\n",
        "    class_mode='categorical',\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "# Define data generators for RGB images with augmentation\n",
        "test_datagen_augmented = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,  # Rotation angle range\n",
        "    width_shift_range=0.2,  # Horizontal shift range\n",
        "    height_shift_range=0.2,  # Vertical shift range\n",
        "    shear_range=0.2,  # Shear intensity\n",
        "    zoom_range=0.2,  # Random zoom range\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    vertical_flip=False,  # Do not flip images vertically\n",
        "    fill_mode='nearest'  # Fill mode for newly created pixels\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=8,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "   )\n",
        "\n",
        "# Define data generators for RGB images with augmentation\n",
        "validation_datagen_augmented = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,  # Rotation angle range\n",
        "    width_shift_range=0.2,  # Horizontal shift range\n",
        "    height_shift_range=0.2,  # Vertical shift range\n",
        "    shear_range=0.2,  # Shear intensity\n",
        "    zoom_range=0.2,  # Random zoom range\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    vertical_flip=False,  # Do not flip images vertically\n",
        "    fill_mode='nearest'  # Fill mode for newly created pixels\n",
        ")\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=8,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxiTCVb-wUHR"
      },
      "source": [
        "# **{'Fractured': 0, 'Non_fractured': 1}**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:16:49.939893Z",
          "iopub.status.busy": "2024-01-12T06:16:49.93946Z",
          "iopub.status.idle": "2024-01-12T06:16:49.945448Z",
          "shell.execute_reply": "2024-01-12T06:16:49.944389Z",
          "shell.execute_reply.started": "2024-01-12T06:16:49.939862Z"
        },
        "id": "JzWCAVy1wUHR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class_indices = train_generator.class_indices\n",
        "print(class_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piHXg60qwUHS"
      },
      "source": [
        "# **Number of images for each class in the training dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:16:54.66822Z",
          "iopub.status.busy": "2024-01-12T06:16:54.667404Z",
          "iopub.status.idle": "2024-01-12T06:16:54.678415Z",
          "shell.execute_reply": "2024-01-12T06:16:54.677519Z",
          "shell.execute_reply.started": "2024-01-12T06:16:54.668184Z"
        },
        "id": "xdj6-VYLwUHS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Count the number of images for each class in the training dataset\n",
        "classes = os.listdir(train_data_dir)\n",
        "for class_name in classes:\n",
        "    class_path = os.path.join(train_data_dir, class_name)\n",
        "    num_images = len(os.listdir(class_path))\n",
        "    print(f\"Class: {class_name}, Number of images: {num_images}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQru1Em0wUHS"
      },
      "source": [
        "# **Check the shape of the images in Train Generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:17:00.387677Z",
          "iopub.status.busy": "2024-01-12T06:17:00.38684Z",
          "iopub.status.idle": "2024-01-12T06:17:00.619173Z",
          "shell.execute_reply": "2024-01-12T06:17:00.6183Z",
          "shell.execute_reply.started": "2024-01-12T06:17:00.387646Z"
        },
        "id": "XYpgcqbKwUHT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Get a batch of images and labels from the train_generator\n",
        "batch = train_generator.next()\n",
        "\n",
        "# Iterate through the batch to check image shapes\n",
        "for i in range(len(batch[0])):\n",
        "    img = batch[0][i]  # Image data\n",
        "    label = batch[1][i]  # Image label\n",
        "\n",
        "    # Get image shape and channels\n",
        "    height, width, channels = img.shape\n",
        "\n",
        "    # Display image shape and channels\n",
        "    print(f\"Image {i+1} - Shape: {width}x{height}x{channels}, Label: {label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO10tCP2wUHT"
      },
      "source": [
        "# **Number of images for each class in the testing dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:17:04.595658Z",
          "iopub.status.busy": "2024-01-12T06:17:04.595022Z",
          "iopub.status.idle": "2024-01-12T06:17:04.602305Z",
          "shell.execute_reply": "2024-01-12T06:17:04.60143Z",
          "shell.execute_reply.started": "2024-01-12T06:17:04.595625Z"
        },
        "id": "3eHWuDYdwUHT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Count the number of images for each class in the testing dataset\n",
        "classes = os.listdir(test_data_dir)\n",
        "for class_name in classes:\n",
        "    class_path = os.path.join(test_data_dir, class_name)\n",
        "    num_images = len(os.listdir(class_path))\n",
        "    print(f\"Class: {class_name}, Number of images: {num_images}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCvkgVTiwUHT"
      },
      "source": [
        "# **Check the shape of the images in Test Generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:17:06.755378Z",
          "iopub.status.busy": "2024-01-12T06:17:06.754536Z",
          "iopub.status.idle": "2024-01-12T06:17:06.803457Z",
          "shell.execute_reply": "2024-01-12T06:17:06.802477Z",
          "shell.execute_reply.started": "2024-01-12T06:17:06.755346Z"
        },
        "id": "c9Mae4O5wUHT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Get a batch of images and labels from the test_generator\n",
        "batch = test_generator.next()\n",
        "\n",
        "# Iterate through the batch to check image shapes\n",
        "for i in range(len(batch[0])):\n",
        "    img = batch[0][i]  # Image data\n",
        "    label = batch[1][i]  # Image label\n",
        "\n",
        "    # Get image shape and channels\n",
        "    height, width, channels = img.shape\n",
        "\n",
        "    # Display image shape and channels\n",
        "    print(f\"Image {i+1} - Shape: {width}x{height}x{channels}, Label: {label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab7F-mGAwUHU"
      },
      "source": [
        "# **Number of images for each class in the validation dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:17:08.004391Z",
          "iopub.status.busy": "2024-01-12T06:17:08.003454Z",
          "iopub.status.idle": "2024-01-12T06:17:08.011848Z",
          "shell.execute_reply": "2024-01-12T06:17:08.010724Z",
          "shell.execute_reply.started": "2024-01-12T06:17:08.004356Z"
        },
        "id": "kNH1iDDqwUHU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Count the number of images for each class in the testing dataset\n",
        "classes = os.listdir(validation_data_dir)\n",
        "for class_name in classes:\n",
        "    class_path = os.path.join(validation_data_dir, class_name)\n",
        "    num_images = len(os.listdir(class_path))\n",
        "    print(f\"Class: {class_name}, Number of images: {num_images}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPCEoTXLwUHU"
      },
      "source": [
        "# **Check the shape of the images in Validation Generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:17:09.739072Z",
          "iopub.status.busy": "2024-01-12T06:17:09.738237Z",
          "iopub.status.idle": "2024-01-12T06:17:09.781634Z",
          "shell.execute_reply": "2024-01-12T06:17:09.780738Z",
          "shell.execute_reply.started": "2024-01-12T06:17:09.739039Z"
        },
        "id": "RwBJhXJqwUHU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Get a batch of images and labels from the validation_generator\n",
        "batch = validation_generator.next()\n",
        "\n",
        "# Iterate through the batch to check image shapes\n",
        "for i in range(len(batch[0])):\n",
        "    img = batch[0][i]  # Image data\n",
        "    label = batch[1][i]  # Image label\n",
        "\n",
        "    # Get image shape and channels\n",
        "    height, width, channels = img.shape\n",
        "\n",
        "    # Display image shape and channels\n",
        "    print(f\"Image {i+1} - Shape: {width}x{height}x{channels}, Label: {label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzzjB0vZwUHU"
      },
      "source": [
        "# **Check for GPU availability**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:17:11.538756Z",
          "iopub.status.busy": "2024-01-12T06:17:11.538124Z",
          "iopub.status.idle": "2024-01-12T06:17:11.925873Z",
          "shell.execute_reply": "2024-01-12T06:17:11.924763Z",
          "shell.execute_reply.started": "2024-01-12T06:17:11.538717Z"
        },
        "id": "9PWzhtM4wUHU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Check for GPU availability\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT available\")\n",
        "\n",
        "# Set TensorFlow to use the GPU device\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
        "    print(\"GPU device configured\")\n",
        "else:\n",
        "    print(\"No GPU device found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kQIb3T4wUHU"
      },
      "source": [
        "# **Model checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:07:22.381745Z",
          "iopub.status.busy": "2024-01-12T07:07:22.381419Z",
          "iopub.status.idle": "2024-01-12T07:07:22.387828Z",
          "shell.execute_reply": "2024-01-12T07:07:22.386937Z",
          "shell.execute_reply.started": "2024-01-12T07:07:22.38172Z"
        },
        "id": "mA4S7-tFwUHU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "model_dir = '/kaggle/working/Checkpoints_densenet201'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "checkpoint_path = model_dir + '/cp.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 save_best_only=True,  # Save only the best model\n",
        "                                                 monitor=\"val_accuracy\",   # Monitor validation loss\n",
        "                                                 mode=\"max\",           # Save the model when validation loss is minimized\n",
        "                                                 verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:17:27.067025Z",
          "iopub.status.busy": "2024-01-12T06:17:27.066221Z",
          "iopub.status.idle": "2024-01-12T06:17:27.073225Z",
          "shell.execute_reply": "2024-01-12T06:17:27.0723Z",
          "shell.execute_reply.started": "2024-01-12T06:17:27.066994Z"
        },
        "id": "qKf5XKHmwUHU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "checkpoint_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49UOTtV3wUHU"
      },
      "source": [
        "# **DenseNet for Feature Extractor**\n",
        "## **1.** DenseNet121\n",
        "## **2.** DenseNet169\n",
        "## **3.** DenseNet201"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:17:37.682116Z",
          "iopub.status.busy": "2024-01-12T06:17:37.681388Z",
          "iopub.status.idle": "2024-01-12T06:17:37.686247Z",
          "shell.execute_reply": "2024-01-12T06:17:37.685232Z",
          "shell.execute_reply.started": "2024-01-12T06:17:37.682081Z"
        },
        "id": "RCDz5F2gwUHV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers, optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:17:44.689266Z",
          "iopub.status.busy": "2024-01-12T06:17:44.688435Z",
          "iopub.status.idle": "2024-01-12T06:17:44.696482Z",
          "shell.execute_reply": "2024-01-12T06:17:44.694992Z",
          "shell.execute_reply.started": "2024-01-12T06:17:44.689235Z"
        },
        "id": "194jQy-fwUHV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def create_model(summary=True):\n",
        "    # apply transfer learning\n",
        "    new_input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "    base_model = DenseNet201(weights='imagenet', include_top=False, input_tensor=new_input) ##MobileNetV3Small(weights='imagenet', include_top=False, input_tensor=new_input)\n",
        "    # add new classifier layers\n",
        "    flat1 = Flatten()(base_model.layers[-1].output)\n",
        "    output = Dense(2, activation='softmax')(flat1)\n",
        "    # define new model\n",
        "    model = Model(inputs=base_model.inputs, outputs=output)\n",
        "    # Modify loss function to 'weighted_binary_crossentropy'\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    if summary:\n",
        "        print(model.summary())\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT2ZKcnqwUHV"
      },
      "source": [
        "# **Model summary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:17:49.537911Z",
          "iopub.status.busy": "2024-01-12T06:17:49.537485Z",
          "iopub.status.idle": "2024-01-12T06:17:57.964528Z",
          "shell.execute_reply": "2024-01-12T06:17:57.963771Z",
          "shell.execute_reply.started": "2024-01-12T06:17:49.537876Z"
        },
        "id": "EMN87a4uwUHV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model = create_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3XCaPI6wUHV"
      },
      "source": [
        "# **Training starts here**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T06:19:21.25298Z",
          "iopub.status.busy": "2024-01-12T06:19:21.252127Z",
          "iopub.status.idle": "2024-01-12T07:07:22.379541Z",
          "shell.execute_reply": "2024-01-12T07:07:22.378512Z",
          "shell.execute_reply.started": "2024-01-12T06:19:21.252944Z"
        },
        "id": "aFF3qSZQwUHV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=25,\n",
        "    callbacks=[cp_callback]\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2y8y25_wUHV"
      },
      "source": [
        "# **Save model history in a CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:07:22.389266Z",
          "iopub.status.busy": "2024-01-12T07:07:22.389Z",
          "iopub.status.idle": "2024-01-12T07:07:22.400987Z",
          "shell.execute_reply": "2024-01-12T07:07:22.400133Z",
          "shell.execute_reply.started": "2024-01-12T07:07:22.389243Z"
        },
        "id": "CVcNX2F6wUHV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Save the training history\n",
        "initial_epoch = 0  # or the actual initial epoch of the first training session\n",
        "saved_history = {\n",
        "    'loss': history.history['loss'],\n",
        "    'accuracy': history.history['accuracy'],\n",
        "    'val_loss': history.history['val_loss'],\n",
        "    'val_accuracy': history.history['val_accuracy'],\n",
        "    # Add other metrics as needed\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:07:22.403109Z",
          "iopub.status.busy": "2024-01-12T07:07:22.402823Z",
          "iopub.status.idle": "2024-01-12T07:07:22.415722Z",
          "shell.execute_reply": "2024-01-12T07:07:22.41485Z",
          "shell.execute_reply.started": "2024-01-12T07:07:22.403075Z"
        },
        "id": "FFfusEkkwUHV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "np.save(\"/kaggle/working/saved_D201history.npy\", saved_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43kOm11ywUHV"
      },
      "source": [
        "# **Again Train the loaded model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:07:22.417112Z",
          "iopub.status.busy": "2024-01-12T07:07:22.416842Z",
          "iopub.status.idle": "2024-01-12T07:07:39.576686Z",
          "shell.execute_reply": "2024-01-12T07:07:39.575587Z",
          "shell.execute_reply.started": "2024-01-12T07:07:22.417089Z"
        },
        "id": "CXl4KsHRwUHV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the latest checkpoint file\n",
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "print(latest_checkpoint)\n",
        "\n",
        "if latest_checkpoint is not None:\n",
        "    # Create a new model instance\n",
        "    loaded_model = create_model(summary=True)\n",
        "\n",
        "    # Load the previously saved weights and silence the warnings\n",
        "    status = loaded_model.load_weights(latest_checkpoint)\n",
        "    status.expect_partial()  # Ignore unrestored variables\n",
        "else:\n",
        "    print(\"No checkpoint file found in the specified directory.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suLNsLRUwUHW"
      },
      "source": [
        "# Load the previous history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:07:39.578305Z",
          "iopub.status.busy": "2024-01-12T07:07:39.578024Z",
          "iopub.status.idle": "2024-01-12T07:07:39.584941Z",
          "shell.execute_reply": "2024-01-12T07:07:39.584012Z",
          "shell.execute_reply.started": "2024-01-12T07:07:39.57828Z"
        },
        "id": "kWSi99cqwUHW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the previous history\n",
        "previous_history = np.load(\"/kaggle/working/saved_D201history.npy\", allow_pickle=True).item()\n",
        "initial_epoch = len(previous_history['loss'])\n",
        "print(initial_epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:09:15.458066Z",
          "iopub.status.busy": "2024-01-12T07:09:15.457131Z",
          "iopub.status.idle": "2024-01-12T07:31:07.114896Z",
          "shell.execute_reply": "2024-01-12T07:31:07.114086Z",
          "shell.execute_reply.started": "2024-01-12T07:09:15.458032Z"
        },
        "id": "XXj-DnH6wUHa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "loaded_model.compile(optimizer=Adam(learning_rate=1e-5), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
        "# Train the model\n",
        "#initial_epoch = 20\n",
        "new_history  = loaded_model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=150,\n",
        "    initial_epoch=initial_epoch,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=30,\n",
        "    callbacks=[cp_callback]\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:31:18.787336Z",
          "iopub.status.busy": "2024-01-12T07:31:18.786953Z",
          "iopub.status.idle": "2024-01-12T07:31:21.920326Z",
          "shell.execute_reply": "2024-01-12T07:31:21.919289Z",
          "shell.execute_reply.started": "2024-01-12T07:31:18.7873Z"
        },
        "id": "xn02oqJawUHa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "loaded_model.save_weights(\"/kaggle/working/dense201.weights.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV1ujM7-wUHa"
      },
      "source": [
        "# **Again save the history after using latest weights in a CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:31:21.923252Z",
          "iopub.status.busy": "2024-01-12T07:31:21.922977Z",
          "iopub.status.idle": "2024-01-12T07:31:21.929543Z",
          "shell.execute_reply": "2024-01-12T07:31:21.928519Z",
          "shell.execute_reply.started": "2024-01-12T07:31:21.923229Z"
        },
        "id": "Spv4zZ67wUHa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Update and save the training history\n",
        "previous_history['loss'].extend(new_history.history['loss'])\n",
        "previous_history['accuracy'].extend(new_history.history['accuracy'])\n",
        "previous_history['val_loss'].extend(new_history.history['val_loss'])\n",
        "previous_history['val_accuracy'].extend(new_history.history['val_accuracy'])\n",
        "# Repeat for other metrics as needed\n",
        "\n",
        "np.save(\"/kaggle/working/saved_D201history.npy\", previous_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFuu9YrXwUHa"
      },
      "source": [
        "# **Accuracy and loss graph of training and validation**\n",
        "## Here, No. of epochs and (xticks & yticks) will be changed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:09:47.096213Z",
          "iopub.status.busy": "2024-01-12T08:09:47.095846Z",
          "iopub.status.idle": "2024-01-12T08:09:47.691509Z",
          "shell.execute_reply": "2024-01-12T08:09:47.690552Z",
          "shell.execute_reply.started": "2024-01-12T08:09:47.096182Z"
        },
        "id": "2OtlskmlwUHa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "import numpy as np\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot Loss\n",
        "train_loss, = plt.plot(previous_history['loss'], label='Train Loss', color='blue')\n",
        "val_loss, = plt.plot(previous_history['val_loss'], label='Validation Loss', color='orange')\n",
        "train_accuracy, = plt.plot(previous_history['accuracy'], label='Train Accuracy',  color='green')\n",
        "val_accuracy, = plt.plot(previous_history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "# Add a title with specified font properties\n",
        "plt.title('Model Performance during Training', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12},pad=10)\n",
        "# Set x-axis label with specified font properties\n",
        "plt.xlabel('No. of Epochs', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
        "\n",
        "# Set x-axis ticks font properties\n",
        "#plt.xticks(np.linspace(0, len(history.history['loss']), num=6), fontname='Serif', weight='bold')\n",
        "\n",
        "plt.xticks(np.linspace(0, 150, num=16), fontname='Serif', weight='bold')\n",
        "\n",
        "\n",
        "# Set y-axis ticks font properties\n",
        "plt.yticks(np.linspace(0, 5, num=11), fontname='Serif', weight='bold')\n",
        "\n",
        "# Set the x-axis and y-axis limits\n",
        "#plt.xlim(0, len(history.history['loss']))\n",
        "\n",
        "plt.xlim(0, 150)\n",
        "plt.ylim(0, 5)\n",
        "\n",
        "# Define custom legend lines with desired line properties\n",
        "legend_lines = [\n",
        "    Line2D([0], [0], color='blue', lw=3),          # Train Loss\n",
        "    Line2D([0], [0], color='orange', lw=3),       # Validation Loss\n",
        "    Line2D([0], [0], color='green', lw=3),        # Train Accuracy\n",
        "    Line2D([0], [0], color='red', lw=3)           # Validation Accuracy\n",
        "]\n",
        "\n",
        "# Place legend outside the graph by adjusting bbox_to_anchor and specifying it to be outside the axes\n",
        "plt.legend(legend_lines, ['Train Loss', 'Validation Loss', 'Train Accuracy', 'Validation Accuracy'],\n",
        "           loc='lower center', bbox_to_anchor=(0.5, 1.1), ncol=5,\n",
        "           prop={'family': 'Serif', 'weight': 'bold', 'size': 8}, frameon=False,\n",
        "           handler_map={Line2D: HandlerLine2D(numpoints=5)})\n",
        "\n",
        "# Adjust padding between x-axis label and x-axis ticks\n",
        "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
        "\n",
        "# Remove top and right spines\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "# Adjust layout to prevent cropping\n",
        "plt.tight_layout()\n",
        "plt.savefig('/kaggle/working/densenet201_accuracy_graph.pdf')  # Save as pdf format\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmzBrtz6wUHa"
      },
      "source": [
        "# **Testing starts here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFQOybibwUHa"
      },
      "source": [
        "## **Load the best checkpoint file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:55:50.463249Z",
          "iopub.status.busy": "2024-01-12T07:55:50.46257Z",
          "iopub.status.idle": "2024-01-12T07:56:07.681179Z",
          "shell.execute_reply": "2024-01-12T07:56:07.680281Z",
          "shell.execute_reply.started": "2024-01-12T07:55:50.463213Z"
        },
        "id": "pOKkhGhCwUHa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the latest checkpoint file\n",
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "print(checkpoint_dir)\n",
        "if latest_checkpoint is not None:\n",
        "    # Create a new model instance\n",
        "    loaded_model = create_model(summary=True)\n",
        "\n",
        "    # Load the previously saved weights and silence the warnings\n",
        "    status = loaded_model.load_weights(latest_checkpoint)\n",
        "    status.expect_partial()  # Ignore unrestored variables\n",
        "else:\n",
        "    print(\"No checkpoint file found in the specified directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:31:39.539321Z",
          "iopub.status.busy": "2024-01-12T07:31:39.539017Z",
          "iopub.status.idle": "2024-01-12T07:31:39.570123Z",
          "shell.execute_reply": "2024-01-12T07:31:39.569288Z",
          "shell.execute_reply.started": "2024-01-12T07:31:39.539294Z"
        },
        "id": "daq0nEJPwUHa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "loaded_model.compile(optimizer=Adam(learning_rate=1e-3), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38969dCTwUHb"
      },
      "source": [
        "# **Evaluate the model on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:56:07.686364Z",
          "iopub.status.busy": "2024-01-12T07:56:07.686039Z",
          "iopub.status.idle": "2024-01-12T07:56:17.571413Z",
          "shell.execute_reply": "2024-01-12T07:56:17.570465Z",
          "shell.execute_reply.started": "2024-01-12T07:56:07.686339Z"
        },
        "id": "NKgPEGnKwUHb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = loaded_model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:56:52.993153Z",
          "iopub.status.busy": "2024-01-12T07:56:52.992793Z",
          "iopub.status.idle": "2024-01-12T07:57:00.346948Z",
          "shell.execute_reply": "2024-01-12T07:57:00.345899Z",
          "shell.execute_reply.started": "2024-01-12T07:56:52.993126Z"
        },
        "id": "7XYDe-pIwUHb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Predict labels for the test set\n",
        "predictions = loaded_model.predict(test_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)  # Get the index of the highest probability class\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "# Display some of the predicted and true classes\n",
        "print(\"Predicted Classes:\", predicted_classes[-10:])  # Display first 10 predicted classes\n",
        "print(\"True Classes:\", true_classes[-10:])  # Display first 10 true classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgyOxRSSwUHb"
      },
      "source": [
        "# **Evaluation Metircs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:57:00.348928Z",
          "iopub.status.busy": "2024-01-12T07:57:00.348592Z",
          "iopub.status.idle": "2024-01-12T07:57:00.36629Z",
          "shell.execute_reply": "2024-01-12T07:57:00.365276Z",
          "shell.execute_reply.started": "2024-01-12T07:57:00.348899Z"
        },
        "id": "pI12T3WSwUHb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(f\"Accuracy: {accuracy_score(true_classes, predicted_classes)}\")\n",
        "print(f\"Precision: {precision_score(true_classes, predicted_classes)}\")\n",
        "print(f\"Recall: {recall_score(true_classes, predicted_classes)}\")\n",
        "print(f\"F1 Score: {f1_score(true_classes, predicted_classes)}\")\n",
        "print(f\"Log Loss: {log_loss(true_classes, predicted_classes)}\")\n",
        "print(f\"Jaccard Score: {jaccard_score(true_classes, predicted_classes)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v-KmoOlwUHb"
      },
      "source": [
        "# **Classification Report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:57:00.3677Z",
          "iopub.status.busy": "2024-01-12T07:57:00.367392Z",
          "iopub.status.idle": "2024-01-12T07:57:00.383403Z",
          "shell.execute_reply": "2024-01-12T07:57:00.382619Z",
          "shell.execute_reply.started": "2024-01-12T07:57:00.367674Z"
        },
        "id": "rWP70AXDwUHb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_classes, predicted_classes,digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-gQo6QMwUHb"
      },
      "source": [
        "# **Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T07:59:57.615178Z",
          "iopub.status.busy": "2024-01-12T07:59:57.614814Z",
          "iopub.status.idle": "2024-01-12T07:59:58.278032Z",
          "shell.execute_reply": "2024-01-12T07:59:58.277049Z",
          "shell.execute_reply.started": "2024-01-12T07:59:57.615149Z"
        },
        "id": "yBywoGwTwUHb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 4.5))\n",
        "# Define the custom palette\n",
        "custom_palette = sns.color_palette(palette='blend:#7AB,#EDA')# Modify the number based on number of classes in the dataset\n",
        "# Define custom font dictionary for title and labels\n",
        "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
        "\n",
        "# Create heatmap with annotations and colormap\n",
        "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_palette,vmin=0,vmax=350,\n",
        "                      xticklabels=['Fractured', 'Non_fractured'], yticklabels=['Fractured', 'Non_fractured'],annot_kws={\"family\": \"Serif\",'weight': 'bold', 'size': 12})\n",
        "\n",
        "# Set x and y labels with the custom font dictionary\n",
        "heatmap.set_xlabel('Predicted Labels', fontdict=font)\n",
        "heatmap.set_ylabel('True Labels', fontdict=font)\n",
        "heatmap.set_title('Fracture Classification', fontdict=font, pad=12)\n",
        "\n",
        "# Set font properties for tick labels on both axes\n",
        "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontname='Serif', fontsize=12)\n",
        "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontname='Serif', fontsize=12)\n",
        "\n",
        "# Create a color bar to indicate the scale\n",
        "cbar = heatmap.collections[0].colorbar\n",
        "cbar.set_label('Count', fontdict=font)\n",
        "cbar.ax.tick_params(labelsize=10)\n",
        "# Adjust padding between x-axis label and x-axis ticks\n",
        "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
        "# Adjust layout to prevent cropping\n",
        "plt.tight_layout()\n",
        "plt.savefig('/kaggle/working/densenet201_cm.pdf')  # Save as pdf format\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvHRJMmowUHb"
      },
      "source": [
        "# **ROC curve for DenseNet201**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:00:01.142884Z",
          "iopub.status.busy": "2024-01-12T08:00:01.142477Z",
          "iopub.status.idle": "2024-01-12T08:00:01.478615Z",
          "shell.execute_reply": "2024-01-12T08:00:01.477609Z",
          "shell.execute_reply.started": "2024-01-12T08:00:01.142835Z"
        },
        "id": "xzj6zhHQwUHb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "\n",
        "# Assuming predicted probabilities for the \"Fractured\" class (class index 1)\n",
        "positive_class_prob = predictions[:, 0]  # Adjust the index based on the column containing the probabilities\n",
        " # Replace 1 with the appropriate index for the \"Fractured\" class\n",
        "\n",
        "# Calculate ROC curve and AUC score\n",
        "fpr, tpr, thresholds = roc_curve(true_classes, positive_class_prob)\n",
        "roc_auc = roc_auc_score(true_classes, positive_class_prob)\n",
        "\n",
        "\n",
        "# Define custom font dictionary for title and labels\n",
        "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Baseline')\n",
        "plt.xlabel('False Positive Rate', fontdict=font)\n",
        "plt.ylabel('True Positive Rate', fontdict=font)\n",
        "plt.title('Fractured Vs Non_fractured', fontdict=font, pad=12)\n",
        "\n",
        "# Create legend entries with bbox\n",
        "legend_handles = [\n",
        "    Patch(facecolor='blue',  label='Fractured Vs Non_fractured (AUC = %0.2f)' % roc_auc),\n",
        "    Patch(facecolor='red',  label='Baseline (AUC = 0.5)')\n",
        "]\n",
        "\n",
        "# Combine loss and accuracy labels with custom legend lines and bbox\n",
        "plt.legend(handles=legend_handles, loc='lower center', ncol=1, prop={'family': 'Serif', 'weight': 'bold', 'size': 10})\n",
        "\n",
        "# Enable grid with customized properties\n",
        "plt.grid(True, linestyle='--', linewidth=0.7, color='gray')\n",
        "\n",
        "# Set x-axis ticks font properties\n",
        "plt.xticks(fontname='Serif', weight='bold')\n",
        "\n",
        "# Set y-axis ticks font properties\n",
        "plt.yticks(fontname='Serif', weight='bold')\n",
        "\n",
        "# Adjust padding between x-axis label and x-axis ticks\n",
        "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVSTseLrwUHb"
      },
      "source": [
        "# **Checking model predictions for random images from test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:00:05.062947Z",
          "iopub.status.busy": "2024-01-12T08:00:05.062029Z",
          "iopub.status.idle": "2024-01-12T08:00:05.454315Z",
          "shell.execute_reply": "2024-01-12T08:00:05.453403Z",
          "shell.execute_reply.started": "2024-01-12T08:00:05.062908Z"
        },
        "id": "MCDM4SSDwUHb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Get random indices for three images\n",
        "random_indices = random.sample(range(len(true_classes)), 3)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i, idx in enumerate(random_indices, 1):\n",
        "    # Load the image\n",
        "    img_path = test_generator.filepaths[idx]\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    # Display the image\n",
        "    plt.subplot(1, 3, i)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Display the true and predicted labels\n",
        "    true_label = \"Fractured\" if true_classes[idx] == 0 else \"Not Fractured\"\n",
        "    predicted_label = \"Fractured\" if predicted_classes[idx] == 0 else \"Not Fractured\"\n",
        "\n",
        "    plt.title(f\"True: {true_label}\\nPredicted: {predicted_label}\",fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfY7nP_1wUHb"
      },
      "source": [
        "# **Explainable AI (GradCAM)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:00:14.967612Z",
          "iopub.status.busy": "2024-01-12T08:00:14.967174Z",
          "iopub.status.idle": "2024-01-12T08:00:14.976418Z",
          "shell.execute_reply": "2024-01-12T08:00:14.975346Z",
          "shell.execute_reply.started": "2024-01-12T08:00:14.967563Z"
        },
        "id": "iLmbQ1vawUHb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to save and display GradCAM\n",
        "def save_and_display_gradcam(img_path, heatmap, alpha=0.7):\n",
        "    # Load the original image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
        "\n",
        "    # Resize heatmap to match the image dimensions\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_PLASMA)\n",
        "\n",
        "    # Apply heatmap on the original image\n",
        "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
        "\n",
        "    # Display the GradCAM visualization using Matplotlib\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('GradCAM', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    # Save the figure\n",
        "    plt.savefig('/kaggle/working/Dens201_gradcam.pdf')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:00:16.019682Z",
          "iopub.status.busy": "2024-01-12T08:00:16.019277Z",
          "iopub.status.idle": "2024-01-12T08:00:16.028133Z",
          "shell.execute_reply": "2024-01-12T08:00:16.027233Z",
          "shell.execute_reply.started": "2024-01-12T08:00:16.019649Z"
        },
        "id": "PdYYdjjFwUHb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "\n",
        "    model.layers[-1].activation = None\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:00:55.198759Z",
          "iopub.status.busy": "2024-01-12T08:00:55.198343Z",
          "iopub.status.idle": "2024-01-12T08:00:56.340958Z",
          "shell.execute_reply": "2024-01-12T08:00:56.339634Z",
          "shell.execute_reply.started": "2024-01-12T08:00:55.198724Z"
        },
        "id": "9B-FfRyqwUHb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        " # make a prediction and visualize grad-cam\n",
        "def make_prediction_and_visualize_():\n",
        "    img_path = '/kaggle/input/bone-fracture-dataset/BoneFractureDataset/testing/fractured/1-rotated1-rotated1-rotated2.jpg'\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (299, 299)) #IMG_WIDTH, IMG_HEIGHT\n",
        "    rescaled_img = img/255.0\n",
        "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
        "\n",
        "\n",
        "    last_conv_layer_name = 'conv5_block32_concat'\n",
        "\n",
        "    # Generate class activation heatmap\n",
        "    heatmap = make_gradcam_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
        "\n",
        "    save_and_display_gradcam(img_path, heatmap)\n",
        "\n",
        "\n",
        "make_prediction_and_visualize_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_EVqBU6wUHb"
      },
      "source": [
        "# **Explainable AI (GradCAM++)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:01:01.069325Z",
          "iopub.status.busy": "2024-01-12T08:01:01.068655Z",
          "iopub.status.idle": "2024-01-12T08:01:01.078252Z",
          "shell.execute_reply": "2024-01-12T08:01:01.077108Z",
          "shell.execute_reply.started": "2024-01-12T08:01:01.069293Z"
        },
        "id": "NRYtrdx8wUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to save and display ScoreCAM\n",
        "def save_and_display_gradcam_plusplus(img_path, heatmap, alpha=0.7):\n",
        "    # Load the original image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
        "\n",
        "    # Resize heatmap to match the image dimensions\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_PLASMA)\n",
        "\n",
        "    # Apply heatmap on the original image\n",
        "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
        "\n",
        "    # Display the GradCAM visualization using Matplotlib\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('GradCAM++', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    # Save the figure\n",
        "    plt.savefig('/kaggle/working/Dens201_gradcam_plusplus.pdf')  # Save as pdf format\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:01:04.284741Z",
          "iopub.status.busy": "2024-01-12T08:01:04.284347Z",
          "iopub.status.idle": "2024-01-12T08:01:04.294374Z",
          "shell.execute_reply": "2024-01-12T08:01:04.293385Z",
          "shell.execute_reply.started": "2024-01-12T08:01:04.284709Z"
        },
        "id": "qOv-ifdPwUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to generate GradCAM++ heatmap\n",
        "def make_gradcam_plusplus_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    model.layers[-1].activation = None\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_output = preds[:, pred_index]\n",
        "        conv_output = last_conv_layer_output[0]\n",
        "\n",
        "    # Get gradients\n",
        "    grads = tape.gradient(class_output, last_conv_layer_output)\n",
        "    pooled_grads = tf.reduce_mean(grads[0], axis=(0, 1, 2))\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "\n",
        "    # Calculate guided gradients\n",
        "    guided_grads = tf.cast(last_conv_layer_output > 0, 'float32') * grads[0]\n",
        "\n",
        "    # Calculate importance weights\n",
        "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
        "\n",
        "    # Generate heatmap\n",
        "    heatmap = tf.reduce_sum(tf.multiply(weights, last_conv_layer_output), axis=-1)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)  # Normalize\n",
        "\n",
        "    return heatmap.numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:02:05.791821Z",
          "iopub.status.busy": "2024-01-12T08:02:05.791201Z",
          "iopub.status.idle": "2024-01-12T08:02:06.947112Z",
          "shell.execute_reply": "2024-01-12T08:02:06.94616Z",
          "shell.execute_reply.started": "2024-01-12T08:02:05.791787Z"
        },
        "id": "QjhDAOmDwUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to make a prediction and visualize GradCAM++\n",
        "def make_prediction_and_visualize_gradcam_plusplus():\n",
        "    img_path = '/kaggle/input/bone-fracture-dataset/BoneFractureDataset/testing/not_fractured/1-rotated2-rotated2-rotated1-rotated1.jpg'\n",
        "\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
        "    rescaled_img = img / 255.0\n",
        "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
        "\n",
        "    last_conv_layer_name = 'conv5_block32_concat'\n",
        "\n",
        "    # Generate GradCAM++ heatmap\n",
        "    heatmap = make_gradcam_plusplus_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
        "\n",
        "    save_and_display_gradcam_plusplus(img_path, heatmap)\n",
        "\n",
        "make_prediction_and_visualize_gradcam_plusplus()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMBbirNuwUHc"
      },
      "source": [
        "# **Explainable AI (ScoreCAM)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:02:10.57944Z",
          "iopub.status.busy": "2024-01-12T08:02:10.578557Z",
          "iopub.status.idle": "2024-01-12T08:02:10.587428Z",
          "shell.execute_reply": "2024-01-12T08:02:10.586339Z",
          "shell.execute_reply.started": "2024-01-12T08:02:10.579408Z"
        },
        "id": "6AKJ-BOowUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to save and display ScoreCAM\n",
        "def save_and_display_scorecam(img_path, heatmap, alpha=0.7):\n",
        "    # Load the original image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
        "\n",
        "    # Resize heatmap to match the image dimensions\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_PLASMA)\n",
        "\n",
        "    # Apply heatmap on the original image\n",
        "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
        "\n",
        "    # Display the ScoreCAM visualization using Matplotlib\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('ScoreCAM', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    # Save the figure\n",
        "    plt.savefig('/kaggle/working/Dens201_scorecam.pdf')  # Save as pdf format\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:02:11.827246Z",
          "iopub.status.busy": "2024-01-12T08:02:11.826904Z",
          "iopub.status.idle": "2024-01-12T08:02:11.836237Z",
          "shell.execute_reply": "2024-01-12T08:02:11.835306Z",
          "shell.execute_reply.started": "2024-01-12T08:02:11.82722Z"
        },
        "id": "PMX2qnJHwUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def make_scorecam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    model.layers[-1].activation = None\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_output = preds[:, pred_index]\n",
        "        conv_output = last_conv_layer_output[0]\n",
        "\n",
        "    # Get the gradients of the predicted class with respect to the output feature map\n",
        "    grads = tape.gradient(class_output, last_conv_layer_output)\n",
        "    guided_grads = tf.cast(grads[0] > 0, 'float32') * grads[0]\n",
        "\n",
        "    # GAP (Global Average Pooling) along the spatial dimensions\n",
        "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
        "\n",
        "    # Calculate the score-weighted activation map\n",
        "    cam = tf.reduce_sum(tf.multiply(weights, conv_output), axis=-1)\n",
        "    cam = tf.maximum(cam, 0)  # ReLU to ensure non-negativity\n",
        "    cam /= tf.reduce_max(cam)  # Normalize\n",
        "\n",
        "    return cam.numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:03:08.133128Z",
          "iopub.status.busy": "2024-01-12T08:03:08.132733Z",
          "iopub.status.idle": "2024-01-12T08:03:09.107562Z",
          "shell.execute_reply": "2024-01-12T08:03:09.106521Z",
          "shell.execute_reply.started": "2024-01-12T08:03:08.133096Z"
        },
        "id": "fnIb5wB4wUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# make a prediction and visualize ScoreCAM\n",
        "def make_prediction_and_visualize_scorecam():\n",
        "    img_path = '/kaggle/input/bone-fracture-dataset/BoneFractureDataset/training/fractured/10-rotated1.jpg'\n",
        "\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (299, 299)) #IMG_WIDTH, IMG_HEIGHT\n",
        "    rescaled_img = img/255.0\n",
        "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
        "\n",
        "    last_conv_layer_name = 'conv5_block32_concat'\n",
        "\n",
        "    # Generate class activation heatmap\n",
        "    heatmap = make_scorecam_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
        "\n",
        "    save_and_display_scorecam(img_path, heatmap)\n",
        "\n",
        "make_prediction_and_visualize_scorecam()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qP8l4LkwUHc"
      },
      "source": [
        "# **Explainable AI (Faster Score-CAM)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:03:15.489304Z",
          "iopub.status.busy": "2024-01-12T08:03:15.488916Z",
          "iopub.status.idle": "2024-01-12T08:03:15.498121Z",
          "shell.execute_reply": "2024-01-12T08:03:15.497057Z",
          "shell.execute_reply.started": "2024-01-12T08:03:15.489273Z"
        },
        "id": "5d8W7IfuwUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to save and display Faster ScoreCAM\n",
        "def save_and_display_faster_scorecam(img_path, heatmap, alpha=0.7):\n",
        "    # Load the original image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
        "\n",
        "    # Resize heatmap to match the image dimensions\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_PLASMA)\n",
        "\n",
        "    # Apply heatmap on the original image\n",
        "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
        "\n",
        "    # Display the Faster ScoreCAM visualization using Matplotlib\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Faster ScoreCAM', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    # Save the figure\n",
        "    plt.savefig('/kaggle/working/Dens201_faster_scorecam.pdf')  # Save as pdf format\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBeU_6PTwUHc"
      },
      "source": [
        "# **Faster ScoreCAM function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:03:17.059114Z",
          "iopub.status.busy": "2024-01-12T08:03:17.058732Z",
          "iopub.status.idle": "2024-01-12T08:03:17.06887Z",
          "shell.execute_reply": "2024-01-12T08:03:17.06779Z",
          "shell.execute_reply.started": "2024-01-12T08:03:17.059081Z"
        },
        "id": "FveyT5awwUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def faster_scorecam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    model.layers[-1].activation = None\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_output = preds[:, pred_index]\n",
        "        conv_output = last_conv_layer_output[0]\n",
        "\n",
        "    # Get the gradient of the predicted class with respect to the output feature map\n",
        "    grads = tape.gradient(class_output, last_conv_layer_output)[0]\n",
        "\n",
        "    # Global average pooling (GAP) to compute weights\n",
        "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
        "\n",
        "    # Reshape the weights to perform matrix multiplication with the convolutional output\n",
        "    weights = tf.reshape(weights, (1, 1, -1))\n",
        "\n",
        "    # Reshape conv_output to match the dimensions for matrix multiplication\n",
        "    conv_output = tf.expand_dims(conv_output, axis=0)\n",
        "    conv_output = tf.expand_dims(conv_output, axis=-1)  # Add a new dimension for matrix multiplication\n",
        "\n",
        "    # Calculate the score-weighted activation map efficiently\n",
        "    cam = tf.matmul(weights, conv_output)\n",
        "    cam = tf.squeeze(cam)\n",
        "    cam = tf.maximum(cam, 0)  # ReLU to ensure non-negativity\n",
        "    cam /= tf.reduce_max(cam)  # Normalize\n",
        "\n",
        "    return cam.numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:05:47.234474Z",
          "iopub.status.busy": "2024-01-12T08:05:47.233484Z",
          "iopub.status.idle": "2024-01-12T08:05:48.296422Z",
          "shell.execute_reply": "2024-01-12T08:05:48.295581Z",
          "shell.execute_reply.started": "2024-01-12T08:05:47.234432Z"
        },
        "id": "YYF1bicYwUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# make a prediction and visualize Faster ScoreCAM\n",
        "def make_prediction_and_visualize_faster_scorecam():\n",
        "    img_path = '/kaggle/input/bone-fracture-dataset/BoneFractureDataset/testing/fractured/2.jpg'\n",
        "\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (299, 299)) #IMG_WIDTH, IMG_HEIGHT\n",
        "    rescaled_img = img/255.0\n",
        "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
        "\n",
        "    last_conv_layer_name = 'conv5_block32_concat'\n",
        "\n",
        "    # Generate class activation heatmap\n",
        "    heatmap = faster_scorecam_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
        "\n",
        "    save_and_display_faster_scorecam(img_path, heatmap)\n",
        "\n",
        "make_prediction_and_visualize_faster_scorecam()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9iDaSO4wUHc"
      },
      "source": [
        "# **Explainable AI (LayerCAM)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:05:52.946041Z",
          "iopub.status.busy": "2024-01-12T08:05:52.945154Z",
          "iopub.status.idle": "2024-01-12T08:05:52.954063Z",
          "shell.execute_reply": "2024-01-12T08:05:52.953165Z",
          "shell.execute_reply.started": "2024-01-12T08:05:52.946006Z"
        },
        "id": "N6Ux4eqBwUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to save and display layercam\n",
        "def save_and_display_layercam(img_path, heatmap, alpha=0.7):\n",
        "    # Load the original image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
        "\n",
        "    # Resize heatmap to match the image dimensions\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_PLASMA)\n",
        "\n",
        "    # Apply heatmap on the original image\n",
        "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
        "\n",
        "    # Display the GradCAM visualization using Matplotlib\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('LayerCAM', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    # Save the figure\n",
        "    plt.savefig('/kaggle/working/Dens201_layercam.pdf')  # Save as pdf format\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:05:54.776588Z",
          "iopub.status.busy": "2024-01-12T08:05:54.776208Z",
          "iopub.status.idle": "2024-01-12T08:05:54.787174Z",
          "shell.execute_reply": "2024-01-12T08:05:54.786149Z",
          "shell.execute_reply.started": "2024-01-12T08:05:54.776547Z"
        },
        "id": "AEfq6Sd2wUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def generate_layercam_heatmap(img_array, model, last_conv_layer_name, target_class_index=None):\n",
        "    model.layers[-1].activation = None\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if target_class_index is None:\n",
        "            target_class_index = tf.argmax(preds[0])\n",
        "        class_output = preds[:, target_class_index]\n",
        "        conv_output = last_conv_layer_output[0]\n",
        "\n",
        "    # Calculate gradients of the predicted class with respect to the output feature map\n",
        "    grads = tape.gradient(class_output, last_conv_layer_output)[0]\n",
        "\n",
        "    # Global average pooling (GAP) to compute weights\n",
        "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
        "\n",
        "    # Reshape the weights to perform matrix multiplication with the convolutional output\n",
        "    weights = tf.reshape(weights, (1, 1, -1))\n",
        "\n",
        "    # Expand dimensions of conv_output for matrix multiplication\n",
        "    conv_output = tf.expand_dims(conv_output, axis=0)\n",
        "    conv_output = tf.expand_dims(conv_output, axis=-1)  # Add a new dimension for matrix multiplication\n",
        "\n",
        "    # Calculate the score-weighted activation map (LayerCAM)\n",
        "    cam = tf.matmul(weights, conv_output)\n",
        "    cam = tf.squeeze(cam)\n",
        "    cam = tf.maximum(cam, 0)  # ReLU to ensure non-negativity\n",
        "    cam /= tf.reduce_max(cam)  # Normalize\n",
        "\n",
        "    return cam.numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:05:56.058237Z",
          "iopub.status.busy": "2024-01-12T08:05:56.057201Z",
          "iopub.status.idle": "2024-01-12T08:05:57.061974Z",
          "shell.execute_reply": "2024-01-12T08:05:57.06101Z",
          "shell.execute_reply.started": "2024-01-12T08:05:56.058198Z"
        },
        "id": "CjgFNRKUwUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# make a prediction and visualize layercam\n",
        "def make_prediction_and_visualize_layercam():\n",
        "    img_path = '/kaggle/input/bone-fracture-dataset/BoneFractureDataset/testing/fractured/1-rotated1-rotated1-rotated2.jpg'\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (299, 299))#IMG_WIDTH, IMG_HEIGHT\n",
        "    rescaled_img = img/255.0\n",
        "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
        "\n",
        "    last_conv_layer_name = 'conv5_block32_concat'\n",
        "\n",
        "    # Generate class activation heatmap\n",
        "    heatmap = generate_layercam_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
        "\n",
        "    save_and_display_layercam(img_path, heatmap)\n",
        "\n",
        "\n",
        "make_prediction_and_visualize_layercam()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfhf3ztxwUHc"
      },
      "source": [
        "# **Explainable AI (Vanilla Saliency)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:06:00.364232Z",
          "iopub.status.busy": "2024-01-12T08:06:00.363838Z",
          "iopub.status.idle": "2024-01-12T08:06:00.372977Z",
          "shell.execute_reply": "2024-01-12T08:06:00.3719Z",
          "shell.execute_reply.started": "2024-01-12T08:06:00.3642Z"
        },
        "id": "PmkjylwDwUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def save_and_display_saliency_map(img_path, saliency_map):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    saliency_map = cv2.resize(saliency_map, (img.shape[1], img.shape[0]))\n",
        "    saliency_map = (saliency_map - saliency_map.min()) / (saliency_map.max() - saliency_map.min())\n",
        "\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * saliency_map), cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    alpha = 0.4\n",
        "    blended = cv2.addWeighted(img, alpha, heatmap, 1 - alpha, 0)\n",
        "\n",
        "\n",
        "    # Display the GradCAM visualization using Matplotlib\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(blended)\n",
        "    plt.title('Vanilla Saliency', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/kaggle/working/Dens201_vanilla_saliency.pdf')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:06:01.938874Z",
          "iopub.status.busy": "2024-01-12T08:06:01.937821Z",
          "iopub.status.idle": "2024-01-12T08:06:01.946704Z",
          "shell.execute_reply": "2024-01-12T08:06:01.945647Z",
          "shell.execute_reply.started": "2024-01-12T08:06:01.938831Z"
        },
        "id": "oii6k3x4wUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def generate_vanilla_saliency_map(img_array, model):\n",
        "    img_tensor = tf.convert_to_tensor(img_array)\n",
        "    img_tensor = tf.expand_dims(img_tensor, axis=0)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(img_tensor)\n",
        "        preds = model(img_tensor)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "\n",
        "        # Get the predicted score for the highest probability class\n",
        "        top_class_score = preds[:, top_pred_index]\n",
        "\n",
        "    # Compute the gradients of the top class score with respect to the input image\n",
        "    grads = tape.gradient(top_class_score, img_tensor)\n",
        "    saliency_map = tf.abs(grads)\n",
        "    saliency_map = tf.reduce_max(saliency_map, axis=-1)\n",
        "\n",
        "    return saliency_map[0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:06:29.896037Z",
          "iopub.status.busy": "2024-01-12T08:06:29.895669Z",
          "iopub.status.idle": "2024-01-12T08:06:31.778986Z",
          "shell.execute_reply": "2024-01-12T08:06:31.777949Z",
          "shell.execute_reply.started": "2024-01-12T08:06:29.896008Z"
        },
        "id": "oViXkyk2wUHc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# make a prediction and visualize Vanilla Saliency\n",
        "def make_prediction_and_visualize_vanilla_saliency():\n",
        "    img_path = '/kaggle/input/bone-fracture-dataset/BoneFractureDataset/testing/fractured/1.jpg'\n",
        "\n",
        "   # Read the image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (299, 299))  # Resize the image to match model input size\n",
        "\n",
        "    # Preprocess the image (normalize pixel values)\n",
        "    img = img / 255.0\n",
        "\n",
        "\n",
        "\n",
        "    # Generate class activation heatmap\n",
        "    saliency_map = generate_vanilla_saliency_map(img, loaded_model)\n",
        "\n",
        "\n",
        "# Display the saliency map overlay\n",
        "    save_and_display_saliency_map(img_path, saliency_map)\n",
        "\n",
        "make_prediction_and_visualize_vanilla_saliency()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWEMXjkawUHc"
      },
      "source": [
        "# **Explainable AI (SmoothGrad)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:06:36.50588Z",
          "iopub.status.busy": "2024-01-12T08:06:36.50548Z",
          "iopub.status.idle": "2024-01-12T08:06:36.514792Z",
          "shell.execute_reply": "2024-01-12T08:06:36.513825Z",
          "shell.execute_reply.started": "2024-01-12T08:06:36.505842Z"
        },
        "id": "UfBLPIivwUHd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def save_and_display_SmoothGrad(img_path, saliency_map):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    saliency_map = cv2.resize(saliency_map, (img.shape[1], img.shape[0]))\n",
        "    saliency_map = (saliency_map - saliency_map.min()) / (saliency_map.max() - saliency_map.min())\n",
        "\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * saliency_map), cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    alpha = 0.4\n",
        "    blended = cv2.addWeighted(img, alpha, heatmap, 1 - alpha, 0)\n",
        "\n",
        "\n",
        "    # Display the GradCAM visualization using Matplotlib\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(blended)\n",
        "    plt.title('Smooth Grad', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/kaggle/working/Dens201_smooth_grad.pdf')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:06:37.507484Z",
          "iopub.status.busy": "2024-01-12T08:06:37.506629Z",
          "iopub.status.idle": "2024-01-12T08:06:37.516986Z",
          "shell.execute_reply": "2024-01-12T08:06:37.516015Z",
          "shell.execute_reply.started": "2024-01-12T08:06:37.507451Z"
        },
        "id": "xh6_rVjAwUHd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def generate_smoothgrad_saliency_map(img_array, model, n=50, sigma=1.0):\n",
        "    img_tensor = tf.convert_to_tensor(img_array)\n",
        "    img_tensor = tf.expand_dims(img_tensor, axis=0)\n",
        "    img_tensor = tf.cast(img_tensor, dtype=tf.float32)  # Convert to float32\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(img_tensor)\n",
        "        preds = model(img_tensor)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "\n",
        "        # Get the predicted score for the highest probability class\n",
        "        top_class_score = preds[:, top_pred_index]\n",
        "\n",
        "    total_gradients = tf.zeros_like(img_tensor)  # Initialize total gradients\n",
        "\n",
        "    for _ in range(n):\n",
        "        # Create perturbed versions of the input image with Gaussian noise\n",
        "        noise = tf.random.normal(shape=img_tensor.shape, mean=0.0, stddev=sigma)\n",
        "        perturbed_img = img_tensor + noise\n",
        "\n",
        "        # Compute gradients for perturbed image\n",
        "        with tf.GradientTape() as perturbed_tape:\n",
        "            perturbed_tape.watch(perturbed_img)\n",
        "            perturbed_preds = model(perturbed_img)\n",
        "            perturbed_top_class_score = perturbed_preds[:, top_pred_index]\n",
        "\n",
        "        # Compute gradients of the top class score w.r.t. perturbed image\n",
        "        perturbed_grads = perturbed_tape.gradient(perturbed_top_class_score, perturbed_img)\n",
        "\n",
        "        # Accumulate gradients\n",
        "        total_gradients += perturbed_grads\n",
        "\n",
        "    # Average gradients over perturbed images\n",
        "    averaged_gradients = total_gradients / n\n",
        "\n",
        "    saliency_map = tf.abs(averaged_gradients)\n",
        "    saliency_map = tf.reduce_max(saliency_map, axis=-1)\n",
        "\n",
        "    return saliency_map[0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T08:06:41.269387Z",
          "iopub.status.busy": "2024-01-12T08:06:41.268418Z",
          "iopub.status.idle": "2024-01-12T08:07:12.351919Z",
          "shell.execute_reply": "2024-01-12T08:07:12.350911Z",
          "shell.execute_reply.started": "2024-01-12T08:06:41.269354Z"
        },
        "id": "4lr_pjymwUHd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def make_prediction_and_visualize_smoothgrad_saliency():\n",
        "    img_path = '/kaggle/input/bone-fracture-dataset/BoneFractureDataset/testing/fractured/1-rotated1-rotated1-rotated2.jpg'\n",
        "\n",
        "\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (299, 299))  # Resize the image to match model input size\n",
        "\n",
        "    # Preprocess the image (normalize pixel values)\n",
        "    img = img / 255.0\n",
        "\n",
        "\n",
        "\n",
        "    # Generate SmoothGrad saliency map\n",
        "    heatmap = generate_smoothgrad_saliency_map(img, loaded_model)\n",
        "\n",
        "    # Display the saliency map overlay\n",
        "    save_and_display_SmoothGrad(img_path, heatmap)\n",
        "\n",
        "\n",
        "# Assuming loaded_model and other necessary components are defined\n",
        "make_prediction_and_visualize_smoothgrad_saliency()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "notebook654860a709",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 2924743,
          "sourceId": 5038715,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30635,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
